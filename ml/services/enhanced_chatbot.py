"""
Enhanced Chatbot Service with LLM Integration
Tr·ª£ l√Ω AI th√¥ng minh v·ªõi Gemini LLM support
"""

import re
import json
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta
import google.generativeai as genai
from core.config import settings
from models.schemas import (
    TransactionRecord, FeatureEngineering, AnomalyDetection,
    ChatbotRequest, ChatbotResponse
)

class EnhancedChatbotService:
    """AI Assistant v·ªõi LLM integration"""
    
    def __init__(self):
        self.context_cache = {}
        
        # Configure Gemini
        if settings.use_gemini and settings.gemini_api_key:
            genai.configure(api_key=settings.gemini_api_key)
            self.gemini_model = genai.GenerativeModel(settings.gemini_model)
            self.use_gemini = True
            print(f"Initialized Gemini model: {settings.gemini_model}")
        else:
            self.use_gemini = False
        
        if not self.use_gemini:
            print("Warning: No Gemini API key found, using rule-based responses")
        
        # System prompt for financial analysis
        self.system_prompt = """
B·∫°n l√† m·ªôt tr·ª£ l√Ω t√†i ch√≠nh th√¥ng minh cho v√≠ blockchain UnityWallet. 
Nhi·ªám v·ª• c·ªßa b·∫°n:
1. Ph√¢n t√≠ch d·ªØ li·ªáu giao d·ªãch v√† ƒë∆∞a ra insights h·ªØu √≠ch
2. G·ª£i √Ω ti·∫øt ki·ªám v√† qu·∫£n l√Ω t√†i ch√≠nh
3. C·∫£nh b√°o v·ªÅ c√°c ho·∫°t ƒë·ªông b·∫•t th∆∞·ªùng
4. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát th√¢n thi·ªán v√† d·ªÖ hi·ªÉu

Quy t·∫Øc:
- Lu√¥n d·ª±a tr√™n d·ªØ li·ªáu th·ª±c t·∫ø ƒë∆∞·ª£c cung c·∫•p
- ƒê∆∞a ra l·ªùi khuy√™n th·ª±c t·∫ø v√† c√≥ th·ªÉ th·ª±c hi·ªán
- Gi·ªØ b·∫£o m·∫≠t th√¥ng tin c√° nh√¢n (mask ƒë·ªãa ch·ªâ)
- S·ª≠ d·ª•ng emoji ph√π h·ª£p ƒë·ªÉ tƒÉng t√≠nh th√¢n thi·ªán
"""
    
    async def process_message(
        self, 
        request: ChatbotRequest,
        transactions: List[TransactionRecord],
        features: FeatureEngineering,
        anomalies: List[AnomalyDetection]
    ) -> ChatbotResponse:
        """X·ª≠ l√Ω tin nh·∫Øn v·ªõi LLM ho·∫∑c rule-based"""
        
        # Prepare context data
        context_data = self._prepare_context(transactions, features, anomalies)
        
        if self.use_gemini:
            response = await self._process_with_gemini(request.message, context_data)
        else:
            response = self._process_with_rules(request.message, context_data)
        
        suggestions = self._generate_smart_suggestions(context_data, request.message)
        
        return ChatbotResponse(
            response=response,
            suggestions=suggestions,
            data=context_data
        )
    
    def _prepare_context(
        self, 
        transactions: List[TransactionRecord],
        features: FeatureEngineering,
        anomalies: List[AnomalyDetection]
    ) -> Dict[str, Any]:
        """Chu·∫©n b·ªã context data cho LLM"""
        
        # Calculate additional insights
        recent_txs = [
            tx for tx in transactions 
            if tx.timestamp >= datetime.now() - timedelta(days=7)
        ]
        
        outgoing_txs = [
            tx for tx in transactions 
            if tx.source == features.account and tx.amount
        ]
        
        incoming_txs = [
            tx for tx in transactions 
            if tx.destination == features.account and tx.amount
        ]
        
        # Spending pattern analysis
        total_spending = sum(tx.amount for tx in outgoing_txs)
        avg_spending_per_tx = total_spending / len(outgoing_txs) if outgoing_txs else 0
        
        # Asset analysis
        spending_by_asset = {}
        for tx in outgoing_txs:
            asset = str(tx.asset) if tx.asset else "XLM"
            spending_by_asset[asset] = spending_by_asset.get(asset, 0) + tx.amount
        
        # Risk assessment
        risk_score = self._calculate_risk_score(features, anomalies)
        
        # Savings potential
        savings_suggestions = self._analyze_savings_potential(features, transactions)
        
        return {
            "account_summary": {
                "total_transactions": features.total_transactions,
                "monthly_avg": features.transactions_per_month,
                "recent_activity": len(recent_txs),
                "total_spending": total_spending,
                "avg_spending": avg_spending_per_tx,
                "spending_by_asset": spending_by_asset
            },
            "risk_analysis": {
                "risk_score": risk_score,
                "anomaly_count": len(anomalies),
                "high_risk_anomalies": [a for a in anomalies if a.confidence_score > 0.8]
            },
            "behavioral_insights": {
                "peak_hours": features.peak_transaction_hours,
                "frequent_destinations": features.frequent_destinations[:3],
                "debt_ratio": features.debt_to_asset_ratio,
                "refund_frequency": features.refund_frequency
            },
            "savings_analysis": savings_suggestions,
            "balance_info": {
                "current_balances": features.avg_balance,
                "volatility": features.balance_volatility
            }
        }
    
    async def _process_with_gemini(self, message: str, context_data: Dict[str, Any]) -> str:
        """X·ª≠ l√Ω v·ªõi Gemini LLM"""
        try:
            # Prepare context for LLM
            context_summary = json.dumps(context_data, indent=2, ensure_ascii=False, default=str)
            
            prompt = f"""
{self.system_prompt}

D·ªØ li·ªáu t√†i kho·∫£n ng∆∞·ªùi d√πng:
{context_summary}

C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {message}

H√£y ph√¢n t√≠ch v√† tr·∫£ l·ªùi m·ªôt c√°ch th√¥ng minh, ƒë∆∞a ra insights v√† suggestions ph√π h·ª£p. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.
"""
            
            response = self.gemini_model.generate_content(prompt)
            return response.text.strip()
            
        except Exception as e:
            print(f"Gemini LLM Error: {e}")
            return self._process_with_rules(message, context_data)
    

    def _process_with_rules(self, message: str, context_data: Dict[str, Any]) -> str:
        """Fallback rule-based processing"""
        
        message_lower = message.lower()
        account_summary = context_data["account_summary"]
        risk_analysis = context_data["risk_analysis"]
        savings_analysis = context_data["savings_analysis"]
        
        # Intent detection
        if any(word in message_lower for word in ["s·ªë d∆∞", "balance", "bao nhi√™u ti·ªÅn"]):
            return self._handle_balance_query(context_data)
        
        elif any(word in message_lower for word in ["ti·∫øt ki·ªám", "saving", "ti·∫øt ki·ªám"]):
            return self._handle_savings_query(savings_analysis)
        
        elif any(word in message_lower for word in ["b·∫•t th∆∞·ªùng", "nguy hi·ªÉm", "risk", "anomaly"]):
            return self._handle_risk_query(risk_analysis)
        
        elif any(word in message_lower for word in ["giao d·ªãch", "transaction", "ho·∫°t ƒë·ªông"]):
            return self._handle_activity_query(account_summary)
        
        else:
            return self._generate_general_response(context_data)
    
    def _handle_balance_query(self, context_data: Dict[str, Any]) -> str:
        """X·ª≠ l√Ω c√¢u h·ªèi v·ªÅ s·ªë d∆∞"""
        balances = context_data["balance_info"]["current_balances"]
        volatility = context_data["balance_info"]["volatility"]
        
        if not balances:
            return "üí∞ T√¥i kh√¥ng th·ªÉ truy c·∫≠p th√¥ng tin s·ªë d∆∞ hi·ªán t·∫°i. H√£y ki·ªÉm tra k·∫øt n·ªëi v·ªõi blockchain."
        
        response = "üí∞ **Th√¥ng tin s·ªë d∆∞ c·ªßa b·∫°n:**\n\n"
        
        for asset, balance in balances.items():
            vol = volatility.get(asset, 0)
            vol_status = "üìà cao" if vol > 100 else "üìä ·ªïn ƒë·ªãnh" if vol > 10 else "üìâ th·∫•p"
            response += f"‚Ä¢ {asset}: {balance:.2f} (bi·∫øn ƒë·ªông {vol_status})\n"
        
        # Add insights
        if len(balances) > 1:
            response += f"\nüí° B·∫°n ƒëang ƒëa d·∫°ng h√≥a v·ªõi {len(balances)} lo·∫°i t√†i s·∫£n - ƒëi·ªÅu n√†y r·∫•t t·ªët!"
        
        return response
    
    def _handle_savings_query(self, savings_analysis: Dict[str, Any]) -> str:
        """X·ª≠ l√Ω c√¢u h·ªèi v·ªÅ ti·∫øt ki·ªám"""
        
        if not savings_analysis["has_potential"]:
            return "üíö Tuy·ªát v·ªùi! Th√≥i quen chi ti√™u c·ªßa b·∫°n ƒë√£ kh√° t·ªëi ∆∞u. H√£y duy tr√¨ nh∆∞ v·∫≠y!"
        
        response = "üí° **G·ª£i √Ω ti·∫øt ki·ªám cho b·∫°n:**\n\n"
        
        for suggestion in savings_analysis["suggestions"]:
            response += f"‚Ä¢ {suggestion}\n"
        
        if savings_analysis["potential_savings"] > 0:
            response += f"\nüìä Ti·ªÅm nƒÉng ti·∫øt ki·ªám: ~{savings_analysis['potential_savings']:.2f} XLM/th√°ng"
        
        return response
    
    def _handle_risk_query(self, risk_analysis: Dict[str, Any]) -> str:
        """X·ª≠ l√Ω c√¢u h·ªèi v·ªÅ r·ªßi ro"""
        
        risk_score = risk_analysis["risk_score"]
        anomaly_count = risk_analysis["anomaly_count"]
        
        if risk_score < 0.3:
            status_emoji = "‚úÖ"
            status_text = "AN TO√ÄN"
        elif risk_score < 0.7:
            status_emoji = "‚ö†Ô∏è"
            status_text = "C·∫¶N CH√ö √ù"
        else:
            status_emoji = "üö®"
            status_text = "NGUY HI·ªÇM"
        
        response = f"{status_emoji} **ƒê√°nh gi√° r·ªßi ro: {status_text}**\n\n"
        response += f"üìä ƒêi·ªÉm r·ªßi ro: {risk_score:.2f}/1.0\n"
        response += f"üîç Ph√°t hi·ªán: {anomaly_count} ho·∫°t ƒë·ªông b·∫•t th∆∞·ªùng\n\n"
        
        if risk_analysis["high_risk_anomalies"]:
            response += "üö® **C·∫£nh b√°o quan tr·ªçng:**\n"
            for anomaly in risk_analysis["high_risk_anomalies"][:2]:
                response += f"‚Ä¢ {anomaly.description}\n"
        
        return response
    
    def _handle_activity_query(self, account_summary: Dict[str, Any]) -> str:
        """X·ª≠ l√Ω c√¢u h·ªèi v·ªÅ ho·∫°t ƒë·ªông"""
        
        total_txs = account_summary["total_transactions"]
        monthly_avg = account_summary["monthly_avg"]
        recent_activity = account_summary["recent_activity"]
        
        response = f"üìä **T·ªïng quan ho·∫°t ƒë·ªông:**\n\n"
        response += f"‚Ä¢ T·ªïng giao d·ªãch: {total_txs}\n"
        response += f"‚Ä¢ Trung b√¨nh/th√°ng: {monthly_avg:.1f}\n"
        response += f"‚Ä¢ Ho·∫°t ƒë·ªông 7 ng√†y qua: {recent_activity}\n\n"
        
        # Activity level assessment
        if monthly_avg >= 30:
            response += "üî• B·∫°n l√† ng∆∞·ªùi d√πng r·∫•t t√≠ch c·ª±c!"
        elif monthly_avg >= 10:
            response += "üìà Ho·∫°t ƒë·ªông c·ªßa b·∫°n kh√° ·ªïn ƒë·ªãnh"
        else:
            response += "üí§ B·∫°n s·ª≠ d·ª•ng v√≠ kh√° √≠t, c√≥ th·ªÉ tƒÉng ho·∫°t ƒë·ªông?"
        
        return response
    
    def _generate_general_response(self, context_data: Dict[str, Any]) -> str:
        """T·∫°o response chung"""
        
        account_summary = context_data["account_summary"]
        risk_analysis = context_data["risk_analysis"]
        
        response = "ü§ñ **T√≥m t·∫Øt t√†i kho·∫£n c·ªßa b·∫°n:**\n\n"
        response += f"üíº T·ªïng giao d·ªãch: {account_summary['total_transactions']}\n"
        response += f"üìä ƒêi·ªÉm r·ªßi ro: {risk_analysis['risk_score']:.2f}/1.0\n"
        response += f"üí∞ T·ªïng chi ti√™u: {account_summary['total_spending']:.2f}\n\n"
        
        response += "üí° **H·ªèi t√¥i v·ªÅ:**\n"
        response += "‚Ä¢ S·ªë d∆∞ v√† t√†i s·∫£n\n"
        response += "‚Ä¢ G·ª£i √Ω ti·∫øt ki·ªám\n" 
        response += "‚Ä¢ Ph√¢n t√≠ch r·ªßi ro\n"
        response += "‚Ä¢ Th√≥i quen giao d·ªãch"
        
        return response
    
    def _calculate_risk_score(
        self, 
        features: FeatureEngineering,
        anomalies: List[AnomalyDetection]
    ) -> float:
        """T√≠nh risk score t·ªïng h·ª£p"""
        
        base_score = 0.0
        
        # Anomaly-based risk
        if anomalies:
            anomaly_score = sum(a.confidence_score for a in anomalies) / len(anomalies)
            base_score += anomaly_score * 0.6
        
        # Frequency-based risk
        if features.transactions_per_month > 100:  # Very high frequency
            base_score += 0.3
        elif features.transactions_per_month > 50:
            base_score += 0.1
        
        # Debt ratio risk
        if features.debt_to_asset_ratio and features.debt_to_asset_ratio > 1.5:
            base_score += 0.2
        
        # Large transaction frequency
        if features.large_transaction_count > features.total_transactions * 0.1:
            base_score += 0.1
        
        return min(1.0, base_score)
    
    def _analyze_savings_potential(
        self, 
        features: FeatureEngineering,
        transactions: List[TransactionRecord]
    ) -> Dict[str, Any]:
        """Ph√¢n t√≠ch ti·ªÅm nƒÉng ti·∫øt ki·ªám"""
        
        suggestions = []
        potential_savings = 0.0
        
        outgoing_txs = [
            tx for tx in transactions 
            if tx.source == features.account and tx.amount
        ]
        
        if not outgoing_txs:
            return {"has_potential": False, "suggestions": [], "potential_savings": 0}
        
        # Analyze spending patterns
        total_spending = sum(tx.amount for tx in outgoing_txs)
        avg_tx_amount = total_spending / len(outgoing_txs)
        
        # High frequency, small amounts -> consolidation opportunity
        if features.transactions_per_month > 30 and avg_tx_amount < 10:
            suggestions.append("üîÑ G·ªôp c√°c giao d·ªãch nh·ªè ƒë·ªÉ ti·∫øt ki·ªám ph√≠ transaction")
            potential_savings += features.transactions_per_month * 0.1  # Estimate fee savings
        
        # Weekend/unusual hour activity
        weekend_txs = [
            tx for tx in outgoing_txs 
            if tx.timestamp.weekday() >= 5
        ]
        
        if len(weekend_txs) > len(outgoing_txs) * 0.3:
            suggestions.append("üìÖ L√™n k·∫ø ho·∫°ch giao d·ªãch v√†o ng√†y th∆∞·ªùng ƒë·ªÉ tr√°nh chi ti√™u b·ªëc ƒë·ªìng")
        
        # Large transaction analysis
        if features.large_transaction_count > 5:
            suggestions.append("üí° Xem x√©t chia nh·ªè c√°c giao d·ªãch l·ªõn ƒë·ªÉ qu·∫£n l√Ω r·ªßi ro t·ªët h∆°n")
        
        # Refund frequency suggests inefficient spending
        if features.refund_frequency > 0.1:  # >10% refund rate
            suggestions.append("üéØ C√¢n nh·∫Øc k·ªπ tr∆∞·ªõc khi giao d·ªãch ƒë·ªÉ gi·∫£m t·∫ßn su·∫•t ho√†n ti·ªÅn")
            potential_savings += total_spending * features.refund_frequency * 0.1
        
        # Peak hour analysis
        if features.peak_transaction_hours and any(h in [2, 3, 4, 5] for h in features.peak_transaction_hours):
            suggestions.append("üò¥ Tr√°nh giao d·ªãch v√†o ban ƒë√™m khi c√≥ th·ªÉ ƒë∆∞a ra quy·∫øt ƒë·ªãnh thi·∫øu c√¢n nh·∫Øc")
        
        return {
            "has_potential": len(suggestions) > 0,
            "suggestions": suggestions,
            "potential_savings": potential_savings
        }
    
    def _generate_smart_suggestions(
        self, 
        context_data: Dict[str, Any], 
        last_message: str
    ) -> List[str]:
        """T·∫°o g·ª£i √Ω th√¥ng minh d·ª±a tr√™n context"""
        
        suggestions = []
        account_summary = context_data["account_summary"]
        risk_analysis = context_data["risk_analysis"]
        
        # Context-aware suggestions
        if "ti·∫øt ki·ªám" in last_message.lower():
            suggestions.extend([
                "Ph√¢n t√≠ch th√≥i quen chi ti√™u c·ªßa t√¥i",
                "T√¥i c√≥ ƒëang l√£ng ph√≠ ti·ªÅn kh√¥ng?",
                "G·ª£i √Ω ƒë·∫ßu t∆∞ an to√†n"
            ])
        elif "r·ªßi ro" in last_message.lower() or "b·∫•t th∆∞·ªùng" in last_message.lower():
            suggestions.extend([
                "L√†m sao ƒë·ªÉ b·∫£o v·ªá t√†i kho·∫£n?",
                "C√°ch thi·∫øt l·∫≠p c·∫£nh b√°o b·∫£o m·∫≠t",
                "Ki·ªÉm tra giao d·ªãch g·∫ßn ƒë√¢y"
            ])
        else:
            # General suggestions based on account state
            if risk_analysis["risk_score"] > 0.5:
                suggestions.append("‚ö†Ô∏è C√≥ ho·∫°t ƒë·ªông b·∫•t th∆∞·ªùng n√†o kh√¥ng?")
            
            if account_summary["monthly_avg"] > 20:
                suggestions.append("üìä Ph√¢n t√≠ch xu h∆∞·ªõng giao d·ªãch")
            
            suggestions.extend([
                "üí∞ S·ªë d∆∞ hi·ªán t·∫°i c·ªßa t√¥i",
                "üí° G·ª£i √Ω ti·∫øt ki·ªám ti·ªÅn",
                "üìà T√≥m t·∫Øt ho·∫°t ƒë·ªông th√°ng n√†y"
            ])
        
        return suggestions[:5]

# Singleton instance
enhanced_chatbot_service = EnhancedChatbotService()
