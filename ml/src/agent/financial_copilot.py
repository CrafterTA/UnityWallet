"""
Financial Copilot - AI Assistant t√≠ch h·ª£p ML v√† LLM
K·∫øt h·ª£p ML insights v·ªõi natural language processing
"""

import json
import pandas as pd
import requests
import subprocess
import time
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta

# Local imports
from ..models.anomaly import AnomalyDetector
from ..models.credit_score import CreditScoreModel  
from ..models.spend_clf import SpendClassifier
from ..rules.insights import InsightGenerator

class FinancialCopilot:
    """
    AI Financial Assistant combining ML insights with LLM conversation
    Optimized for Acer Nitro 5 with local LLM support
    Supports Vietnamese language and multiple LLM providers
    """
    
    def __init__(self, models_path: str = "artifacts/models", 
                 optimize_for_nitro5: bool = True):
        # Load ML models
        self.anomaly_detector = AnomalyDetector(models_path)
        self.credit_scorer = CreditScoreModel(models_path) 
        self.spend_classifier = SpendClassifier(models_path)
        self.insight_generator = InsightGenerator()
        
        # Nitro 5 optimization
        self.nitro5_mode = optimize_for_nitro5
        if self.nitro5_mode:
            self._setup_nitro5_config()
        
        # Initialize LLM providers
        self._setup_llm_providers()
        
        # Vietnamese financial prompts
        self.prompts = {
            "greeting": """Xin ch√†o! T√¥i l√† tr·ª£ l√Ω t√†i ch√≠nh AI c·ªßa Unity Wallet. 
                         T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:
                         ‚Ä¢ üìä Ph√¢n t√≠ch giao d·ªãch v√† chi ti√™u
                         ‚Ä¢ üîç Ph√°t hi·ªán gian l·∫≠n
                         ‚Ä¢ üí∞ T∆∞ v·∫•n ti·∫øt ki·ªám v√† ƒë·∫ßu t∆∞  
                         ‚Ä¢ üìà ƒê√°nh gi√° t√≠n d·ª•ng
                         B·∫°n c·∫ßn h·ªó tr·ª£ g√¨ ·∫°?""",
                         
            "analysis": """D·ª±a tr√™n d·ªØ li·ªáu giao d·ªãch c·ªßa b·∫°n:
                          {ml_insights}
                          
                          H√£y tr·∫£ l·ªùi c√¢u h·ªèi: {user_question}
                          
                          ƒê∆∞a ra l·ªùi khuy√™n c·ª• th·ªÉ v√† th·ª±c t·∫ø cho ng∆∞·ªùi Vi·ªát Nam.""",
                          
            "fraud_alert": """‚ö†Ô∏è C·∫¢NH B√ÅO GIAN L·∫¨N:
                             Ph√°t hi·ªán giao d·ªãch b·∫•t th∆∞·ªùng:
                             {transaction_details}
                             
                             ƒê√°nh gi√° r·ªßi ro: {risk_level}
                             L√Ω do: {reason}
                             
                             B·∫°n c√≥ nh·∫≠n ra giao d·ªãch n√†y kh√¥ng?""",
                             
            "savings_advice": """üí° L·ªúI KHUY√äN TI·∫æT KI·ªÜM:
                               Ph√¢n t√≠ch chi ti√™u c·ªßa b·∫°n:
                               {spending_analysis}
                               
                               ƒê·ªÅ xu·∫•t ti·∫øt ki·ªám:
                               {savings_suggestions}"""
        }
    
    def _setup_nitro5_config(self):
        """Setup optimal configuration for Acer Nitro 5"""
        self.nitro5_config = {
            "primary_model": "phi3:mini",        # Best balance cho Nitro 5
            "fallback_model": "gemma:2b",        # Speed backup
            "cloud_backup": "groq_llama",        # Free cloud option
            
            # Performance settings
            "max_tokens": 300,                   # Shorter responses 
            "temperature": 0.7,                  # Good balance
            "context_window": 2048,              # Enough cho financial data
            "timeout_seconds": 10,               # Reasonable cho Nitro 5
            
            # Model routing cho different tasks
            "routing": {
                "simple_queries": "gemma:2b",     # "Bao nhi√™u ti·ªÅn?"
                "complex_analysis": "phi3:mini",   # Financial analysis
                "fraud_detection": "phi3:mini",    # C·∫ßn reasoning
                "savings_advice": "phi3:mini"      # Context understanding
            }
        }
    
    def _setup_llm_providers(self):
        """Setup LLM providers for Financial Copilot"""
        self.llm_providers = {
            "ollama": {
                "enabled": True,
                "models": ["phi3:mini", "gemma:2b", "llama3:8b"],
                "endpoint": "http://localhost:11434"
            },
            "groq": {
                "enabled": False,  # Requires API key
                "models": ["llama3-8b-8192", "gemma-7b-it"],
                "api_key": None
            },
            "openai": {
                "enabled": False,  # Requires API key
                "models": ["gpt-3.5-turbo", "gpt-4"],
                "api_key": None
            }
        }
    
    def _check_ollama_available(self) -> bool:
        """Check if Ollama is running"""
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=5)
            return response.status_code == 200
        except:
            return False
    
    def _get_ollama_models(self) -> List[str]:
        """Get available Ollama models"""
        try:
            result = subprocess.run(['ollama', 'list'], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')[1:]  # Skip header
                models = [line.split()[0] for line in lines if line.strip()]
                return models
        except:
            pass
        return []
    
    def _ollama_chat(self, model: str, prompt: str, context: str = "") -> str:
        """Chat with Ollama model"""
        try:
            full_prompt = f"{context}\n\n{prompt}" if context else prompt
            
            result = subprocess.run([
                'ollama', 'run', model, '--', full_prompt
            ], capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                return result.stdout.strip()
            else:
                return f"Error: {result.stderr.strip()}"
                
        except subprocess.TimeoutExpired:
            return "Error: Response timeout"
        except Exception as e:
            return f"Error: {str(e)}"
    
    def _route_to_best_model(self, intent: str, complexity: str) -> str:
        """Route to best available model based on intent and complexity"""
        
        if not self.nitro5_mode:
            # Default routing if not optimized for Nitro 5
            return "phi3:mini"
        
        routing = self.nitro5_config["routing"]
        available_models = self._get_ollama_models()
        
        # Get preferred model for this intent
        if intent in routing:
            preferred = routing[intent]
        elif complexity == "simple":
            preferred = "gemma:2b"
        elif complexity == "complex":
            preferred = "phi3:mini"
        else:
            preferred = self.nitro5_config["primary_model"]
        
        # Check if preferred model is available
        if preferred in available_models:
            return preferred
        
        # Fallback hierarchy
        fallback_order = ["phi3:mini", "gemma:2b", "llama3:8b"]
        for model in fallback_order:
            if model in available_models:
                return model
        
        # No local models available
        return None
    
    def chat(self, user_message: str, user_id: str, transactions_df: pd.DataFrame) -> Dict[str, Any]:
        """
        Main chat interface combining ML analysis with LLM response
        """
        
        # 1. Analyze user intent
        intent = self._analyze_intent(user_message)
        
        # 2. Get ML insights based on intent  
        ml_context = self._get_ml_context(intent, user_id, transactions_df)
        
        # 3. Route to best model
        model = self._route_to_best_model(intent, ml_context.get('complexity', 'medium'))
        
        if not model:
            return {
                "response": "Xin l·ªói, t√¥i kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi AI model. Vui l√≤ng th·ª≠ l·∫°i sau.",
                "intent": intent,
                "ml_insights": ml_context,
                "model_used": None,
                "timestamp": datetime.now().isoformat()
            }
        
        # 4. Generate context-aware prompt
        prompt = self._build_prompt(intent, user_message, ml_context)
        
        # 5. Get LLM response
        llm_response = self._ollama_chat(model, prompt)
        
        # 6. Format final response
        return {
            "response": llm_response,
            "intent": intent,
            "ml_insights": ml_context,
            "model_used": model,
            "suggestions": self._generate_suggestions(intent, ml_context),
            "timestamp": datetime.now().isoformat()
        }
    
    def _analyze_intent(self, user_message: str) -> str:
        """Analyze user intent from message"""
        message_lower = user_message.lower()
        
        # Fraud detection keywords
        if any(word in message_lower for word in ['l·ª´a ƒë·∫£o', 'gian l·∫≠n', 'fraud', 'b·∫•t th∆∞·ªùng', 'ƒë√°ng nghi']):
            return 'fraud_detection'
        
        # Credit score keywords  
        if any(word in message_lower for word in ['t√≠n d·ª•ng', 'credit', 'ƒëi·ªÉm t√≠n d·ª•ng', 'vay v·ªën']):
            return 'credit_analysis'
        
        # Spending analysis keywords
        if any(word in message_lower for word in ['chi ti√™u', 'spending', 'ti√™u d√πng', 'ph√¢n t√≠ch']):
            return 'spending_analysis'
        
        # Savings advice keywords
        if any(word in message_lower for word in ['ti·∫øt ki·ªám', 'saving', 'ƒë·∫ßu t∆∞', 'invest']):
            return 'savings_advice'
        
        # Simple queries
        if any(word in message_lower for word in ['bao nhi√™u', 's·ªë d∆∞', 'balance', 't·ªïng']):
            return 'simple_queries'
        
        return 'general'
    
    def _get_ml_context(self, intent: str, user_id: str, transactions_df: pd.DataFrame) -> Dict[str, Any]:
        """Get ML insights based on intent"""
        
        if transactions_df.empty:
            return {"complexity": "simple", "insights": "Kh√¥ng c√≥ d·ªØ li·ªáu giao d·ªãch"}
        
        context = {"complexity": "medium"}
        
        try:
            if intent == 'fraud_detection':
                # Run anomaly detection
                anomalies = self.anomaly_detector.detect_anomalies(transactions_df)
                context.update({
                    "complexity": "complex",
                    "anomalies_count": len(anomalies),
                    "risk_level": "High" if len(anomalies) > 0 else "Low",
                    "suspicious_transactions": anomalies.to_dict('records') if len(anomalies) > 0 else []
                })
                
            elif intent == 'credit_analysis':
                # Run credit scoring  
                credit_score = self.credit_scorer.predict_credit_score(transactions_df)
                context.update({
                    "complexity": "complex", 
                    "credit_score": credit_score,
                    "credit_rating": self._get_credit_rating(credit_score)
                })
                
            elif intent == 'spending_analysis':
                # Run spending classification
                spending_insights = self.spend_classifier.analyze_spending(transactions_df)
                context.update({
                    "complexity": "medium",
                    "spending_by_category": spending_insights,
                    "total_spending": transactions_df['amount'].sum(),
                    "transaction_count": len(transactions_df)
                })
                
            elif intent == 'savings_advice':
                # Generate savings insights
                insights = self.insight_generator.generate_insights(transactions_df)
                context.update({
                    "complexity": "medium",
                    "savings_potential": insights.get('savings_potential', 0),
                    "recommendations": insights.get('recommendations', [])
                })
                
            else:
                # Simple queries
                context.update({
                    "complexity": "simple",
                    "balance": transactions_df['amount'].sum(),
                    "recent_transactions": len(transactions_df)
                })
                
        except Exception as e:
            context["error"] = f"ML analysis error: {str(e)}"
            
        return context
    
    def _build_prompt(self, intent: str, user_message: str, ml_context: Dict[str, Any]) -> str:
        """Build context-aware prompt for LLM"""
        
        # Base prompt in Vietnamese
        if intent == 'fraud_detection':
            prompt_template = self.prompts["fraud_alert"]
            return prompt_template.format(
                transaction_details=ml_context.get('suspicious_transactions', []),
                risk_level=ml_context.get('risk_level', 'Unknown'),
                reason="Ph√°t hi·ªán b·ªüi ML model"
            )
            
        elif intent in ['spending_analysis', 'credit_analysis', 'savings_advice']:
            prompt_template = self.prompts["analysis"] 
            ml_insights = f"""
            üìä Ph√¢n t√≠ch ML:
            - Intent: {intent}
            - D·ªØ li·ªáu: {ml_context}
            """
            return prompt_template.format(
                ml_insights=ml_insights,
                user_question=user_message
            )
        
        else:
            # General conversation
            return f"""
            B·∫°n l√† tr·ª£ l√Ω t√†i ch√≠nh AI c·ªßa Unity Wallet. 
            C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {user_message}
            
            D·ªØ li·ªáu t·ª´ ML: {ml_context}
            
            H√£y tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát m·ªôt c√°ch th√¢n thi·ªán v√† h·ªØu √≠ch.
            """
    
    def _get_credit_rating(self, score: float) -> str:
        """Convert credit score to rating"""
        if score >= 0.8:
            return "Xu·∫•t s·∫Øc"
        elif score >= 0.7:
            return "T·ªët"
        elif score >= 0.6:
            return "Kh√°"
        elif score >= 0.5:
            return "Trung b√¨nh"
        else:
            return "C·∫ßn c·∫£i thi·ªán"
    
    def _generate_suggestions(self, intent: str, ml_context: Dict[str, Any]) -> List[str]:
        """Generate actionable suggestions"""
        
        suggestions = []
        
        if intent == 'fraud_detection':
            if ml_context.get('risk_level') == 'High':
                suggestions = [
                    "üîí Kh√≥a th·∫ª ngay l·∫≠p t·ª©c",
                    "üìû G·ªçi hotline ng√¢n h√†ng", 
                    "üìç B√°o c√°o v·ªã tr√≠ b·∫•t th∆∞·ªùng"
                ]
        
        elif intent == 'savings_advice':
            suggestions = [
                "üí∞ Thi·∫øt l·∫≠p m·ª•c ti√™u ti·∫øt ki·ªám",
                "üìä Theo d√µi chi ti√™u h√†ng ng√†y",
                "üéØ T·∫°o ng√¢n s√°ch chi ti√™u"
            ]
        
        elif intent == 'credit_analysis':
            score = ml_context.get('credit_score', 0)
            if score < 0.6:
                suggestions = [
                    "üìà C·∫£i thi·ªán l·ªãch s·ª≠ thanh to√°n",
                    "üí≥ S·ª≠ d·ª•ng th·∫ª t√≠n d·ª•ng h·ª£p l√Ω",
                    "üè¶ X√¢y d·ª±ng m·ªëi quan h·ªá v·ªõi ng√¢n h√†ng"
                ]
        
        return suggestions
        
        # 3. Generate LLM response with ML context
        response = self._generate_llm_response(user_message, ml_context)
        
        # 4. Add action suggestions if needed
        actions = self._suggest_actions(intent, ml_context)
        
        return {
            "response": response,
            "intent": intent,
            "actions": actions,
            "ml_insights": ml_context,
            "timestamp": datetime.now().isoformat()
        }
    
    def _analyze_intent(self, message: str) -> str:
        """Classify user intent from message"""
        
        message_lower = message.lower()
        
        # Intent patterns in Vietnamese
        intent_patterns = {
            "spending_summary": ["t√≥m t·∫Øt", "chi ti√™u", "th√°ng n√†y", "b√°o c√°o", "th·ªëng k√™"],
            "savings_advice": ["ti·∫øt ki·ªám", "g·ª£i √Ω", "l·ªùi khuy√™n", "gi·∫£m chi ti√™u", "t·ªëi ∆∞u"],
            "fraud_check": ["gian l·∫≠n", "b·∫•t th∆∞·ªùng", "an to√†n", "kh√≥a th·∫ª", "c·∫£nh b√°o"],
            "category_analysis": ["danh m·ª•c", "ph√¢n lo·∫°i", "bi·ªÉu ƒë·ªì", "xu h∆∞·ªõng"],
            "credit_inquiry": ["ƒëi·ªÉm t√≠n d·ª•ng", "vay v·ªën", "t√≠n nhi·ªám", "credit score"],
            "general_question": ["l√† g√¨", "nh∆∞ th·∫ø n√†o", "gi·∫£i th√≠ch", "t·∫°i sao"]
        }
        
        for intent, keywords in intent_patterns.items():
            if any(keyword in message_lower for keyword in keywords):
                return intent
        
        return "general_question"
    
    def _get_ml_context(self, intent: str, user_id: str, transactions_df: pd.DataFrame) -> Dict[str, Any]:
        """Get relevant ML insights based on intent"""
        
        context = {}
        
        if intent in ["spending_summary", "category_analysis"]:
            # Get spending insights
            insights = self.insight_generator.generate_insights(user_id, transactions_df)
            context.update(insights)
            
            # Add category breakdown
            user_txns = transactions_df[transactions_df['user_id'] == user_id]
            if not user_txns.empty:
                context["category_spending"] = self._analyze_categories(user_txns)
        
        elif intent == "fraud_check":
            # Get anomaly analysis
            user_txns = transactions_df[transactions_df['user_id'] == user_id]
            if not user_txns.empty:
                latest_txn = user_txns.iloc[-1].to_dict()
                anomaly_result = self.anomaly_detector.predict_anomaly(
                    user_id, latest_txn, transactions_df
                )
                context["fraud_analysis"] = anomaly_result
        
        elif intent == "credit_inquiry":
            # Get credit score analysis
            credit_result = self.credit_scorer.predict_score(user_id, transactions_df)
            context["credit_analysis"] = credit_result
        
        elif intent == "savings_advice":
            # Get spending patterns for savings advice
            insights = self.insight_generator.generate_insights(user_id, transactions_df)
            context["savings_opportunities"] = self._identify_savings_opportunities(insights)
        
        return context
    
    def _generate_llm_response(self, user_message: str, ml_context: Dict) -> str:
        """Generate natural language response using LLM with ML context"""
        
        # Format ML context for LLM
        context_text = self._format_ml_context(ml_context)
        
        # Create prompt
        prompt = f"""
        {self.system_prompt}
        
        D·ªØ li·ªáu ph√¢n t√≠ch ML:
        {context_text}
        
        C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {user_message}
        
        H√£y tr·∫£ l·ªùi d·ª±a tr√™n d·ªØ li·ªáu ph√¢n t√≠ch tr√™n:
        """
        
        try:
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": f"D·ªØ li·ªáu: {context_text}\n\nC√¢u h·ªèi: {user_message}"}
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            # Fallback to rule-based response
            return self._generate_fallback_response(user_message, ml_context)
    
    def _format_ml_context(self, context: Dict) -> str:
        """Format ML context for LLM consumption"""
        
        formatted_parts = []
        
        if "total_amount" in context:
            formatted_parts.append(f"T·ªïng chi ti√™u: {context['total_amount']:,.0f} VND")
        
        if "category_spending" in context:
            cat_text = ", ".join([f"{k}: {v:,.0f} VND" for k, v in context['category_spending'].items()])
            formatted_parts.append(f"Chi ti√™u theo danh m·ª•c: {cat_text}")
        
        if "fraud_analysis" in context:
            fraud = context["fraud_analysis"]
            formatted_parts.append(f"Ph√¢n t√≠ch gian l·∫≠n: {fraud.get('risk_level', 'B√¨nh th∆∞·ªùng')}")
        
        if "credit_analysis" in context:
            credit = context["credit_analysis"]
            formatted_parts.append(f"ƒêi·ªÉm t√≠n d·ª•ng: {credit.get('score', 'N/A')}")
        
        return ". ".join(formatted_parts)
    
    def _generate_fallback_response(self, user_message: str, ml_context: Dict) -> str:
        """Fallback response when LLM is not available"""
        
        if "total_amount" in ml_context:
            return f"T·ªïng chi ti√™u c·ªßa b·∫°n l√† {ml_context['total_amount']:,.0f} VND. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n ph√¢n t√≠ch chi ti·∫øt h∆°n."
        
        return "T√¥i ƒëang ph√¢n t√≠ch d·ªØ li·ªáu c·ªßa b·∫°n. Vui l√≤ng ƒë·ª£i m·ªôt ch√∫t ho·∫∑c h·ªèi c·ª• th·ªÉ h∆°n."
    
    def _analyze_categories(self, transactions_df: pd.DataFrame) -> Dict[str, float]:
        """Analyze spending by category"""
        
        if transactions_df.empty:
            return {}
        
        # Classify transactions
        category_spending = {}
        for _, txn in transactions_df.iterrows():
            category = self.spend_classifier.predict_category(
                txn.get('description', ''),
                txn.get('merchant', ''),
                txn.get('mcc', ''),
                txn.get('amount', 0)
            )
            
            if category not in category_spending:
                category_spending[category] = 0
            category_spending[category] += float(txn.get('amount', 0))
        
        return category_spending
    
    def _identify_savings_opportunities(self, insights: Dict) -> List[str]:
        """Identify potential savings opportunities"""
        
        opportunities = []
        
        if insights.get('high_frequency_merchants'):
            opportunities.append("C√≥ th·ªÉ ti·∫øt ki·ªám t·ª´ c√°c merchant th∆∞·ªùng xuy√™n")
        
        if insights.get('weekend_spending_high'):
            opportunities.append("Chi ti√™u cu·ªëi tu·∫ßn cao, c√≥ th·ªÉ c√¢n nh·∫Øc gi·∫£m")
        
        return opportunities
    
    def _suggest_actions(self, intent: str, ml_context: Dict) -> List[Dict[str, str]]:
        """Suggest actionable items based on intent and context"""
        
        actions = []
        
        if intent == "fraud_check":
            fraud = ml_context.get("fraud_analysis", {})
            if fraud.get("is_anomaly", False):
                actions.append({
                    "type": "security",
                    "title": "Kh√≥a th·∫ª t·∫°m th·ªùi",
                    "description": "Ph√°t hi·ªán giao d·ªãch b·∫•t th∆∞·ªùng",
                    "action": "lock_card"
                })
        
        elif intent == "savings_advice":
            actions.append({
                "type": "savings",
                "title": "Xem b√°o c√°o chi ti·∫øt",
                "description": "Ph√¢n t√≠ch chi ti√™u theo danh m·ª•c",
                "action": "view_spending_report"
            })
        
        return actions

# Usage Examples
def demo_financial_copilot():
    """Demo examples"""
    
    # Sample data
    transactions = pd.DataFrame([
        {"user_id": "user123", "amount": 50000, "description": "ƒÉn ph·ªü", "merchant": "Ph·ªü H·ªìng"},
        {"user_id": "user123", "amount": 2000000, "description": "mua laptop", "merchant": "FPT Shop"}
    ])
    
    copilot = FinancialCopilot()
    
    # Example conversations
    examples = [
        "T√≥m t·∫Øt chi ti√™u th√°ng n√†y c·ªßa t√¥i",
        "C√≥ giao d·ªãch b·∫•t th∆∞·ªùng n√†o kh√¥ng?",
        "G·ª£i √Ω ti·∫øt ki·ªám 15% cho t√¥i",
        "ƒêi·ªÉm t√≠n d·ª•ng c·ªßa t√¥i nh∆∞ th·∫ø n√†o?"
    ]
    
    for question in examples:
        response = copilot.chat(question, "user123", transactions)
        print(f"Q: {question}")
        print(f"A: {response['response']}")
        print(f"Actions: {response['actions']}")
        print("---")

if __name__ == "__main__":
    demo_financial_copilot()
